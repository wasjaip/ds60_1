{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu5ZbNVITBY7"
   },
   "source": [
    "## Описание проекта\n",
    "\n",
    "Интернет-сервис запускает функционал общения с клиентами у себя на сайте. Необходимо построить модель детектирования негативных сообщений для дальнейшей обработки сервисной службой.\n",
    "\n",
    "### Цели\n",
    "- Обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности сообщений.\n",
    "- Построить модель со значением метрики качества *F1* не меньше 0.75.\n",
    "\n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели.\n",
    "3. Сделать выводы.\n",
    "\n",
    "\n",
    "### Описание данных\n",
    "Данные находятся в файле `toxic_comments.csv`.\n",
    "- **text** - текст комментария,\n",
    "- **toxic** - целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install accelerate -U\n",
    "# !pip install -q -U watermark\n",
    "# !pip install time\n",
    "# !pip install torchsummary\n",
    "# !pip re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:11.022356600Z",
     "start_time": "2023-06-15T22:25:10.673612900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.3\n",
      "IPython version      : 8.7.0\n",
      "\n",
      "numpy       : 1.23.5\n",
      "pandas      : 1.5.2\n",
      "torch       : 2.0.1+cu117\n",
      "transformers: 4.25.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:11.241352700Z",
     "start_time": "2023-06-15T22:25:10.679142400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "библиотеки ок\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import transformers\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score,f1_score\n",
    "    from transformers import BertTokenizer, BertModel,BertConfig\n",
    "    import time\n",
    "    import re\n",
    "\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModelForMaskedLM,AutoModel\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from transformers import  BertForSequenceClassification, Trainer, TrainingArguments\n",
    "    from torchsummary import summary\n",
    "\n",
    "    print('библиотеки ок')\n",
    "except:\n",
    "    print('Грузим pip')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:11.242355200Z",
     "start_time": "2023-06-15T22:25:10.700648600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "t6Uhb4zMTBY-",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:11.269354200Z",
     "start_time": "2023-06-15T22:25:10.707344100Z"
    }
   },
   "outputs": [],
   "source": [
    "# посчитаем общее времечко, чтобы ревью прошло быстренько=)\n",
    "start_time_all = time.time()\n",
    "rn=1977\n",
    "# размер семпла\n",
    "sam=1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFuXyKPDScQ1"
   },
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "o9CynISfZ3pS",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.379565700Z",
     "start_time": "2023-06-15T22:25:10.715352800Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv',index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.442408300Z",
     "start_time": "2023-06-15T22:25:17.380529300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "баланс классов [143106  16186]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Подсчет количества значений\n",
    "value_counts = data['toxic'].value_counts()\n",
    "\n",
    "# Построение графика countplot\n",
    "sns.countplot(x='toxic', data=data, order=value_counts.index)\n",
    "\n",
    "plt.xlabel('review toxic')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "class_counts = np.bincount(data['toxic'])\n",
    "print('баланс классов',class_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.589502800Z",
     "start_time": "2023-06-15T22:25:17.430370800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ВИдим большой дисбаланс классов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "GPU доступна\n",
      "Устройство: NVIDIA GeForce RTX 3070\n",
      "Всего памяти:  8.0 GB\n",
      "Используется памяти:  1.28 GB\n",
      "Зарезервировано памяти:  7.14 GB\n",
      "Свободной памяти:  0.86 GB\n"
     ]
    }
   ],
   "source": [
    "# Проверяю, доступна ли видеокарта\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU доступна')\n",
    "    print('Устройство:', torch.cuda.get_device_name())\n",
    "\n",
    "    # Выводим информацию о видеопамяти\n",
    "    total_mem = torch.cuda.get_device_properties(device).total_memory\n",
    "    reserved_mem = torch.cuda.memory_reserved(device)\n",
    "    allocated_mem = torch.cuda.memory_allocated(device)\n",
    "    free_mem = total_mem - reserved_mem\n",
    "\n",
    "    print('Всего памяти: ', round(total_mem / 1024**3, 2), 'GB')\n",
    "    print('Используется памяти: ', round(allocated_mem / 1024**3, 2), 'GB')\n",
    "    print('Зарезервировано памяти: ', round(reserved_mem / 1024**3, 2), 'GB')\n",
    "    print('Свободной памяти: ', round(free_mem / 1024**3, 2), 'GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('GPU не доступна, используется CPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.600948500Z",
     "start_time": "2023-06-15T22:25:17.596421100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  toxic\n0     Sometime back, I just happened to log on to ww...      0\n1     \"\\n\\nThe latest edit is much better, don't mak...      0\n2     \" October 2007 (UTC)\\n\\nI would think you'd be...      0\n3     Thanks for the tip on the currency translation...      0\n4     I would argue that if content on the Con in co...      0\n...                                                 ...    ...\n1495       Sounds perfect! I'm going to work on it now.      0\n1496  \"\\n\\nFirst of all the albanian migration in th...      0\n1497  Hamboards \\n\\nI have removed the speedy deleti...      0\n1498  If you are a scholar, it would seem that you w...      0\n1499  Another one \\n\\nDo you people create these pag...      0\n\n[1500 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sometime back, I just happened to log on to ww...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"\\n\\nThe latest edit is much better, don't mak...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\" October 2007 (UTC)\\n\\nI would think you'd be...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Thanks for the tip on the currency translation...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I would argue that if content on the Con in co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>Sounds perfect! I'm going to work on it now.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>\"\\n\\nFirst of all the albanian migration in th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>Hamboards \\n\\nI have removed the speedy deleti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>If you are a scholar, it would seem that you w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>Another one \\n\\nDo you people create these pag...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обрежем\n",
    "data = data.sample(sam).reset_index(drop=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.706686400Z",
     "start_time": "2023-06-15T22:25:17.602948800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# model =AutoModelForMaskedLM.from_pretrained('unitary/toxic-bert')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('unitary/toxic-bert',num_labels=2)\n",
    "# model = BertForSequenceClassification.from_pretrained('unitary/toxic-bert')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wW9bpLtqTBZB",
    "outputId": "060a65c9-3497-46a5-bf84-c235a989c538",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:17.707686300Z",
     "start_time": "2023-06-15T22:25:17.634098700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"unitary/toxic-bert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"toxic\",\n",
      "    \"1\": \"severe_toxic\",\n",
      "    \"2\": \"obscene\",\n",
      "    \"3\": \"threat\",\n",
      "    \"4\": \"insult\",\n",
      "    \"5\": \"identity_hate\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"identity_hate\": 5,\n",
      "    \"insult\": 4,\n",
      "    \"obscene\": 2,\n",
      "    \"severe_toxic\": 1,\n",
      "    \"threat\": 3,\n",
      "    \"toxic\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at unitary/toxic-bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"unitary/toxic-bert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"toxic\",\n",
      "    \"1\": \"severe_toxic\",\n",
      "    \"2\": \"obscene\",\n",
      "    \"3\": \"threat\",\n",
      "    \"4\": \"insult\",\n",
      "    \"5\": \"identity_hate\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"identity_hate\": 5,\n",
      "    \"insult\": 4,\n",
      "    \"obscene\": 2,\n",
      "    \"severe_toxic\": 1,\n",
      "    \"threat\": 3,\n",
      "    \"toxic\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"unitary/toxic-bert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"toxic\",\n",
      "    \"1\": \"severe_toxic\",\n",
      "    \"2\": \"obscene\",\n",
      "    \"3\": \"threat\",\n",
      "    \"4\": \"insult\",\n",
      "    \"5\": \"identity_hate\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"identity_hate\": 5,\n",
      "    \"insult\": 4,\n",
      "    \"obscene\": 2,\n",
      "    \"severe_toxic\": 1,\n",
      "    \"threat\": 3,\n",
      "    \"toxic\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\admin/.cache\\huggingface\\hub\\models--unitary--toxic-bert\\snapshots\\5cc53435803a6e6f1ac8e4b243910d3bf26803ff\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"unitary/toxic-bert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"toxic\",\n",
      "    \"1\": \"severe_toxic\",\n",
      "    \"2\": \"obscene\",\n",
      "    \"3\": \"threat\",\n",
      "    \"4\": \"insult\",\n",
      "    \"5\": \"identity_hate\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"identity_hate\": 5,\n",
      "    \"insult\": 4,\n",
      "    \"obscene\": 2,\n",
      "    \"severe_toxic\": 1,\n",
      "    \"threat\": 3,\n",
      "    \"toxic\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretrained_path = \"DeepPavlov/rubert-base-cased\"\n",
    "\n",
    "\n",
    "# Загрузите модель и токенизатор\n",
    "model = transformers.AutoModel.from_pretrained('unitary/toxic-bert')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = transformers.AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "\n",
    "# Создаем классификатор на основе модели BERT\n",
    "class BertForSequenceClassification(transformers.BertPreTrainedModel):\n",
    "    # Конструктор класса\n",
    "    def __init__(self, config):\n",
    "        # Вызов конструктора родительского класса и инициализация с конфигурацией BERT\n",
    "        super().__init__(config)\n",
    "        # Число классов задается из конфигурации BERT\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = model  # используйте загруженную модель BERT\n",
    "        # Создание слоя dropout с заданной в конфигурации вероятностью\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        # Создание классификатора как полносвязного слоя\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "     # Определение прямого прохода модели\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,            # Идентификаторы токенов входных данных\n",
    "        attention_mask=None,       # Маска внимания для входных данных\n",
    "        token_type_ids=None,       # Идентификаторы типов токенов для входных данных\n",
    "        position_ids=None,         # Идентификаторы позиций для входных данных\n",
    "        head_mask=None,            # Маска для скрытия некоторых голов внимания\n",
    "        inputs_embeds=None,        # Предварительно встроенные представления входных данных\n",
    "        labels=None,               # Метки для вычисления функции потерь\n",
    "        output_attentions=None,    # Флаг, определяющий, следует ли возвращать внимание\n",
    "        output_hidden_states=None, # Флаг, определяющий, следует ли возвращать скрытое состояние\n",
    "        return_dict=None,          # Флаг, определяющий, следует ли возвращать данные в виде словаря\n",
    "    ):\n",
    "        # Если return_dict не предоставлен, используется значение из конфигурации\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        # Прямой проход через модель BERT\n",
    "        outputs = self.bert(\n",
    "\n",
    "            input_ids,                      # Идентификаторы токенов входных данных\n",
    "            attention_mask=attention_mask,  # Маска внимания для входных данных\n",
    "            token_type_ids=token_type_ids,  # Идентификаторы типов токенов для входных данных\n",
    "            position_ids=position_ids,      # Идентификаторы позиций для входных данных\n",
    "            head_mask=head_mask,            # Маска для скрытия некоторых голов внимания\n",
    "            inputs_embeds=inputs_embeds,    # Предварительно встроенные представления входных данных\n",
    "            output_attentions=output_attentions,        # Флаг, определяющий, следует ли возвращать внимание\n",
    "            output_hidden_states=output_hidden_states,  # Флаг, определяющий, следует ли возвращать скрытое состояние\n",
    "            return_dict=return_dict,        # Флаг, определяющий, следует ли возвращать данные в виде словаряattention_mask=attention_mask,\n",
    "\n",
    "        )\n",
    "        # Извлечение выхода пула из выходов BERT\n",
    "        pooled_output = outputs[1]\n",
    "        # Применение dropout к выходу пула\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        # Пропускание выхода пула через классификатор\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "         # Если предоставлены метки, вычисление потерь\n",
    "        if labels is not None:\n",
    "            # Если число меток равно 1, то задача регрессии\n",
    "            if self.num_labels == 1:\n",
    "                # задача регрессии\n",
    "                loss_fct = torch.nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                # Используем кросс-энтропию для вычисления потери в задаче классификации\n",
    "                loss_fct = torch.nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            # Если не нужно возвращать словарь, то возвращаем кортеж из потерь, логитов и других выходных данных\n",
    "            if not return_dict:\n",
    "                output = (logits,) + outputs[2:]\n",
    "                return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "            # Иначе возвращаем выходные данные в виде объекта SequenceClassifierOutput\n",
    "            return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "                loss=loss,\n",
    "                logits=logits,\n",
    "                hidden_states=outputs.hidden_states,\n",
    "                attentions=outputs.attentions,\n",
    "            )\n",
    "        # Если метки не предоставлены, то просто возвращаем логиты и другие выходные данные\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return output\n",
    "        # Иначе возвращаем выходные данные в виде объекта SequenceClassifierOutput\n",
    "        return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "# Используйте классификатор\n",
    "model = BertForSequenceClassification(model.config)\n",
    "\n",
    "# Теперь вы можете использовать свой классификатор в процессе обучен"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.079421Z",
     "start_time": "2023-06-15T22:25:17.637689500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это дает более детальный обзор модели, включая размеры входов и выходов для каждого слоя и количество параметров."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([30522, 768])\n",
      "bert.embeddings.position_embeddings.weight torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "bert.pooler.dense.weight torch.Size([768, 768])\n",
      "bert.pooler.dense.bias torch.Size([768])\n",
      "classifier.weight torch.Size([6, 768])\n",
      "classifier.bias torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Параметры и слои\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.083421100Z",
     "start_time": "2023-06-15T22:25:20.047183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NmGop4GoTBZC",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.084420400Z",
     "start_time": "2023-06-15T22:25:20.057249100Z"
    }
   },
   "outputs": [],
   "source": [
    " # Определение класса CustomDataset, который наследуется от класса Dataset в PyTorch\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    # Определение функции __init__, которая выполняется при создании объекта CustomDataset\n",
    "    # Эта функция принимает два аргумента: encodings и labels\n",
    "    def __init__(self, encodings, labels):\n",
    "        # Сохранение данных кодирования и меток в переменных экземпляра класса\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    # Определение функции __getitem__, которая выполняется при получении элемента датасета по индексу\n",
    "    def __getitem__(self, idx):\n",
    "        # Формирование элемента датасета, преобразовывая все значения в тензоры PyTorch\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Добавление метки для данного элемента\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        # Возвращение сформированного элемента\n",
    "        return item\n",
    "\n",
    "    # Определение функции __len__, которая возвращает количество элементов в датасете\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую, валидационную и тестовую выборки\n",
    "train_data, remaining = train_test_split(data, test_size=0.2, random_state=42)\n",
    "valid_data, test_data = train_test_split(remaining, test_size=0.5, random_state=42)\n"
   ],
   "metadata": {
    "id": "1sHdNb8MTBZC",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.084420400Z",
     "start_time": "2023-06-15T22:25:20.064239600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "((1200, 2), (150, 2), (150, 2))"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,valid_data.shape,test_data.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP_RzGZ4TBZC",
    "outputId": "d6f33e7e-9e47-4f88-c6d3-001e41beea88",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.094419800Z",
     "start_time": "2023-06-15T22:25:20.073939600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# ТОкинезация длинна 512 и все возвращаем в вектора pyTorch\n",
    "train_encodings = tokenizer(train_data['text'].to_list(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "valid_encodings = tokenizer(valid_data['text'].to_list(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_data['text'].to_list(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Ooo7Xi9BTBZD",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.554424600Z",
     "start_time": "2023-06-15T22:25:20.080426200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train_labels = train_data['toxic'].to_list()\n",
    "valid_labels = valid_data['toxic'].to_list()\n",
    "test_labels = test_data['toxic'].to_list()"
   ],
   "metadata": {
    "id": "rzyV2UIcTBZD",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.559895600Z",
     "start_time": "2023-06-15T22:25:20.554424600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "NRirncUfTBZD",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.566926100Z",
     "start_time": "2023-06-15T22:25:20.560919500Z"
    }
   },
   "outputs": [],
   "source": [
    "# дата сеты для тренера\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "valid_dataset = CustomDataset(valid_encodings, valid_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "#чуть переделел чтобы логи и график сходимости сделать\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  # директория для вывода результатов\n",
    "    num_train_epochs=3,                      # общее количество эпох обучения\n",
    "    per_device_train_batch_size=8,          # размер пакета данных на каждом устройстве во время обучения\n",
    "    per_device_eval_batch_size=32,           # размер пакета данных на каждом устройстве во время оценки\n",
    "    warmup_steps=500,                        # количество шагов разогрева для планировщика скорости обучения\n",
    "    weight_decay=0.01,                       # сила убывания веса\n",
    "    logging_dir='./logs',                    # директория для хранения журналов\n",
    "    load_best_model_at_end=True,             # загрузка тренировочной модели для теста\n",
    "    logging_steps=10,                        # журнал и сохранение весов каждые `logging_steps`\n",
    "    evaluation_strategy='steps',             # оценка  регистрируется при каждом  `logging_steps`\n",
    "    save_strategy='steps',                   # контрольные точки модели сохраняются  `logging_steps`\n",
    "    save_steps=500,                          # контрольные точки модели сохраняются каждые `save_steps`\n",
    ")\n"
   ],
   "metadata": {
    "id": "swsZ-VXHTBZE",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.629413700Z",
     "start_time": "2023-06-15T22:25:20.567914200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# # Функция метрики\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'f1_score': f1_score(y_true=labels, y_pred=predictions, average='weighted')}"
   ],
   "metadata": {
    "id": "5jJ1v_XmTBZE",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.652428Z",
     "start_time": "2023-06-15T22:25:20.588920900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "LAKlM0KKTBZE",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:25:20.933117500Z",
     "start_time": "2023-06-15T22:25:20.593385800Z"
    }
   },
   "outputs": [],
   "source": [
    "# тренер\n",
    "trainer = Trainer(\n",
    "    model=model,                         # инициированная модель  Transformers, которую требуется обучить\n",
    "    args=training_args,                   # определенные выше аргументы обучения\n",
    "    train_dataset=train_dataset,         # обучающий датасет\n",
    "    eval_dataset=valid_dataset,          # датасет для оценки(валидации)\n",
    "    compute_metrics=compute_metrics,    # функция обратного вызова, которая вычисляет интересующие нас метрики\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\PycharmProjects\\venv\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1200\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 450\n",
      "  Number of trainable parameters = 109486854\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/450 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 7s\n",
      "Wall time: 5min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=450, training_loss=0.2428837798991137, metrics={'train_runtime': 307.4883, 'train_samples_per_second': 11.708, 'train_steps_per_second': 1.463, 'total_flos': 947233817395200.0, 'train_loss': 0.2428837798991137, 'epoch': 3.0})"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# тренеруем модель\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zhoI7QF3TBZF",
    "outputId": "69b3b4e6-12f7-4fba-df5b-99616d49fa2f",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:28.449561500Z",
     "start_time": "2023-06-15T22:25:20.934115800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0JicHhHeTBZF",
    "outputId": "f782399d-ba4b-49e2-abfb-620bf3b36c82",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:30.890743100Z",
     "start_time": "2023-06-15T22:30:28.450561200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/5 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.03336578980088234,\n 'eval_f1_score': 0.9866666666666667,\n 'eval_runtime': 2.4251,\n 'eval_samples_per_second': 61.854,\n 'eval_steps_per_second': 2.062,\n 'epoch': 3.0}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# валидируем\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 266 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Отображение графика сходимости\n",
    "log_df = pd.DataFrame(trainer.state.log_history)\n",
    "# Исключение строк с NaN значениями\n",
    "# Замена NaN значениями ближайших соседей\n",
    "df = pd.DataFrame()\n",
    "df['loss'] = log_df['loss'].fillna(method='ffill').fillna(method='bfill')\n",
    "df['eval_loss'] = log_df['eval_loss'].fillna(method='ffill').fillna(method='bfill')\n",
    "# Построение графиков\n",
    "plt.plot(log_df['epoch'], df['loss'], label='loss')\n",
    "plt.plot(log_df['epoch'], df['eval_loss'], label='eval_loss')\n",
    "\n",
    "# Настройки осей и легенды\n",
    "plt.title('Train, Valid Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "# Отображение графика\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:31.174585900Z",
     "start_time": "2023-06-15T22:30:30.889719800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Тест"
   ],
   "metadata": {
    "collapsed": false,
    "id": "RKhcygvuTBZG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "PPrwGrOFTBZG",
    "outputId": "e38a1da9-13ab-48af-a5ae-e92fe29ac73f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:33.321443800Z",
     "start_time": "2023-06-15T22:30:31.172552100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 150\n",
      "  Batch size = 32\n",
      "C:\\Temp\\ipykernel_7132\\817352437.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.14 s\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.04960707202553749,\n 'eval_f1_score': 0.9809237816516098,\n 'eval_runtime': 2.139,\n 'eval_samples_per_second': 70.126,\n 'eval_steps_per_second': 2.338,\n 'epoch': 3.0}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1Mg9lkRTBZH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-CwtYsI2TBZH",
    "outputId": "ec7a83b4-8c64-4708-e12d-c7b41397cff3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:33.326646400Z",
     "start_time": "2023-06-15T22:30:33.322440600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "код завершен, общее время 5 мин\n"
     ]
    }
   ],
   "source": [
    "# общее время выполения кода(для комфорта проверки и заботы о ревьювере=)))....код завершен, общее время 6 мин\n",
    "time_all=time.time()-start_time_all\n",
    "print('код завершен, общее время',int(time_all/60),'мин')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caqW8R_Vmgd-"
   },
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug0JpSWZmo16"
   },
   "source": [
    "о итогу выполнения проекта, были получены эмбеддинги от BERT, на основе которых были созданы модели обучения предсказания токсичности комментариев.( итог на большой выборке)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PIdtwIOETBZX",
    "ExecuteTime": {
     "end_time": "2023-06-15T22:30:33.332916800Z",
     "start_time": "2023-06-15T22:30:33.327644200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2023-06-08T01:49:10.239Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-08T01:51:06.824Z"
   },
   {
    "duration": 4050,
    "start_time": "2023-06-08T02:09:25.051Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-08T02:11:18.850Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-08T02:12:34.248Z"
   },
   {
    "duration": 2186,
    "start_time": "2023-06-08T02:12:35.677Z"
   },
   {
    "duration": 314,
    "start_time": "2023-06-08T02:12:57.445Z"
   },
   {
    "duration": 783,
    "start_time": "2023-06-08T02:13:18.858Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-08T02:13:20.332Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-08T02:14:02.322Z"
   },
   {
    "duration": 139,
    "start_time": "2023-06-08T02:15:45.277Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-08T02:15:46.030Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-08T02:15:55.293Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-08T02:15:57.053Z"
   },
   {
    "duration": 2870,
    "start_time": "2023-06-08T02:16:17.357Z"
   },
   {
    "duration": 8987,
    "start_time": "2023-06-08T02:16:21.613Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-08T02:16:30.602Z"
   },
   {
    "duration": 339,
    "start_time": "2023-06-08T02:16:30.606Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-08T02:16:30.947Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-08T02:16:44.779Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-08T18:58:25.795Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-08T18:58:26.001Z"
   },
   {
    "duration": 1477,
    "start_time": "2023-06-08T18:58:26.381Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-08T18:58:27.861Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-08T18:58:28.382Z"
   },
   {
    "duration": 254,
    "start_time": "2023-06-08T18:58:31.165Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-08T18:58:48.963Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-08T18:58:49.556Z"
   },
   {
    "duration": 587,
    "start_time": "2023-06-08T19:02:39.111Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-08T19:02:39.812Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-08T19:02:46.509Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-08T19:02:46.834Z"
   },
   {
    "duration": 1085,
    "start_time": "2023-06-08T19:02:47.673Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-08T19:02:48.760Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-08T19:02:49.256Z"
   },
   {
    "duration": 304,
    "start_time": "2023-06-08T19:02:50.477Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-08T19:02:51.465Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-08T19:02:52.432Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-08T19:02:53.142Z"
   },
   {
    "duration": 3419,
    "start_time": "2023-06-08T19:02:57.273Z"
   },
   {
    "duration": 2981,
    "start_time": "2023-06-08T19:03:00.697Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-08T19:03:03.680Z"
   },
   {
    "duration": 511,
    "start_time": "2023-06-08T19:03:03.691Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-08T19:03:04.610Z"
   },
   {
    "duration": 894039,
    "start_time": "2023-06-08T19:03:07.430Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-08T19:18:01.471Z"
   },
   {
    "duration": 262,
    "start_time": "2023-06-08T19:18:01.476Z"
   },
   {
    "duration": 84,
    "start_time": "2023-06-08T19:18:01.742Z"
   },
   {
    "duration": 160,
    "start_time": "2023-06-08T19:18:01.831Z"
   },
   {
    "duration": 7142,
    "start_time": "2023-06-08T19:18:02.000Z"
   },
   {
    "duration": 2017,
    "start_time": "2023-06-08T19:18:09.198Z"
   },
   {
    "duration": 108,
    "start_time": "2023-06-08T19:18:11.227Z"
   },
   {
    "duration": 104,
    "start_time": "2023-06-08T19:18:11.340Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-08T19:18:11.447Z"
   },
   {
    "duration": 952403,
    "start_time": "2023-06-08T19:18:11.459Z"
   },
   {
    "duration": 143146,
    "start_time": "2023-06-08T19:34:03.864Z"
   },
   {
    "duration": 64,
    "start_time": "2023-06-08T19:36:27.019Z"
   },
   {
    "duration": 45,
    "start_time": "2023-06-08T19:36:27.084Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-08T19:36:27.140Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-08T19:36:27.153Z"
   },
   {
    "duration": 674,
    "start_time": "2023-06-08T19:36:27.166Z"
   },
   {
    "duration": 26953,
    "start_time": "2023-06-08T19:36:27.843Z"
   },
   {
    "duration": 884,
    "start_time": "2023-06-08T19:36:54.797Z"
   },
   {
    "duration": 47,
    "start_time": "2023-06-08T19:36:55.690Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-08T19:36:55.740Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-08T19:36:55.758Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-08T19:36:55.765Z"
   },
   {
    "duration": 53,
    "start_time": "2023-06-08T19:36:55.779Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-08T19:36:55.834Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-08T19:36:55.854Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-08T19:36:55.863Z"
   },
   {
    "duration": 80,
    "start_time": "2023-06-08T19:36:55.884Z"
   },
   {
    "duration": 67,
    "start_time": "2023-06-08T19:36:55.967Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-08T19:36:56.036Z"
   },
   {
    "duration": 64,
    "start_time": "2023-06-08T19:36:56.056Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-09T14:09:31.136Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-09T14:09:31.781Z"
   },
   {
    "duration": 2188,
    "start_time": "2023-06-09T14:09:33.312Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-09T14:09:36.390Z"
   },
   {
    "duration": 4775,
    "start_time": "2023-06-11T16:48:34.680Z"
   },
   {
    "duration": 316,
    "start_time": "2023-06-11T16:48:39.457Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T16:48:39.775Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-11T16:48:40.325Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T16:49:10.568Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T16:49:11.838Z"
   },
   {
    "duration": 2438,
    "start_time": "2023-06-11T16:49:13.617Z"
   },
   {
    "duration": 34,
    "start_time": "2023-06-11T16:49:16.058Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:49:16.225Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T16:49:51.656Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T16:50:15.554Z"
   },
   {
    "duration": 819,
    "start_time": "2023-06-11T16:50:17.441Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T16:50:37.620Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-11T16:50:38.237Z"
   },
   {
    "duration": 840,
    "start_time": "2023-06-11T16:50:39.240Z"
   },
   {
    "duration": 35,
    "start_time": "2023-06-11T16:50:40.082Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:50:41.031Z"
   },
   {
    "duration": 4110,
    "start_time": "2023-06-11T16:50:42.016Z"
   },
   {
    "duration": 241,
    "start_time": "2023-06-11T16:50:49.213Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:51:05.583Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T16:51:10.407Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-11T16:51:11.757Z"
   },
   {
    "duration": 2826,
    "start_time": "2023-06-11T16:51:16.021Z"
   },
   {
    "duration": 9160,
    "start_time": "2023-06-11T16:51:18.853Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:51:28.015Z"
   },
   {
    "duration": 4786,
    "start_time": "2023-06-11T16:51:42.773Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-11T16:51:47.561Z"
   },
   {
    "duration": 827,
    "start_time": "2023-06-11T16:51:47.564Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-11T16:51:48.394Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T16:51:48.443Z"
   },
   {
    "duration": 4380,
    "start_time": "2023-06-11T16:51:48.450Z"
   },
   {
    "duration": 261,
    "start_time": "2023-06-11T16:51:52.833Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:51:53.096Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T16:51:53.103Z"
   },
   {
    "duration": 39,
    "start_time": "2023-06-11T16:51:53.115Z"
   },
   {
    "duration": 6296,
    "start_time": "2023-06-11T16:51:53.156Z"
   },
   {
    "duration": 2674,
    "start_time": "2023-06-11T16:51:59.458Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-11T16:52:02.134Z"
   },
   {
    "duration": 18585,
    "start_time": "2023-06-11T16:52:02.155Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-11T16:52:20.744Z"
   },
   {
    "duration": 4748,
    "start_time": "2023-06-11T21:51:12.791Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-11T21:51:17.540Z"
   },
   {
    "duration": 2425,
    "start_time": "2023-06-11T21:51:17.557Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-11T21:51:19.983Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T21:51:20.023Z"
   },
   {
    "duration": 4060,
    "start_time": "2023-06-11T21:51:20.030Z"
   },
   {
    "duration": 229,
    "start_time": "2023-06-11T21:51:24.092Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T21:51:24.323Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-11T21:51:24.328Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-11T21:51:24.353Z"
   },
   {
    "duration": 3716,
    "start_time": "2023-06-11T21:51:24.369Z"
   },
   {
    "duration": 9225,
    "start_time": "2023-06-11T21:51:28.087Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T21:51:37.313Z"
   },
   {
    "duration": 320,
    "start_time": "2023-06-11T21:51:37.320Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-11T21:51:37.652Z"
   },
   {
    "duration": 259813,
    "start_time": "2023-06-11T21:51:37.671Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T21:55:57.541Z"
   },
   {
    "duration": 35,
    "start_time": "2023-06-11T21:55:57.551Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T21:55:57.588Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T21:55:57.596Z"
   },
   {
    "duration": 1753,
    "start_time": "2023-06-11T21:55:57.604Z"
   },
   {
    "duration": 385,
    "start_time": "2023-06-11T21:55:59.360Z"
   },
   {
    "duration": 94,
    "start_time": "2023-06-11T21:55:59.752Z"
   },
   {
    "duration": 103,
    "start_time": "2023-06-11T21:55:59.856Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T21:55:59.961Z"
   },
   {
    "duration": 402046,
    "start_time": "2023-06-11T21:55:59.974Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.022Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.023Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.024Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.025Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.027Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.027Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.029Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.029Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.030Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.031Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.032Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.033Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.035Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.037Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.038Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.039Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.040Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.044Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.045Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.046Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:02:42.047Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T22:02:50.203Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T22:02:50.729Z"
   },
   {
    "duration": 824,
    "start_time": "2023-06-11T22:02:51.888Z"
   },
   {
    "duration": 43,
    "start_time": "2023-06-11T22:02:52.714Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T22:02:54.274Z"
   },
   {
    "duration": 4296,
    "start_time": "2023-06-11T22:02:54.813Z"
   },
   {
    "duration": 262,
    "start_time": "2023-06-11T22:02:59.111Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T22:02:59.375Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T22:02:59.381Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-11T22:03:02.955Z"
   },
   {
    "duration": 5574,
    "start_time": "2023-06-11T22:03:06.527Z"
   },
   {
    "duration": 2966,
    "start_time": "2023-06-11T22:03:12.103Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T22:03:15.071Z"
   },
   {
    "duration": 324,
    "start_time": "2023-06-11T22:03:15.076Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-11T22:03:15.401Z"
   },
   {
    "duration": 260203,
    "start_time": "2023-06-11T22:03:17.674Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T22:07:37.880Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-11T22:07:37.887Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-11T22:10:10.373Z"
   },
   {
    "duration": 1832,
    "start_time": "2023-06-11T22:10:12.084Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T22:10:13.917Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T22:11:28.370Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T22:11:30.486Z"
   },
   {
    "duration": 5783,
    "start_time": "2023-06-11T22:11:33.076Z"
   },
   {
    "duration": 614,
    "start_time": "2023-06-11T22:11:42.056Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T22:11:43.221Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T22:11:52.269Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T22:11:53.444Z"
   },
   {
    "duration": 856799,
    "start_time": "2023-06-11T22:12:00.024Z"
   },
   {
    "duration": 141544,
    "start_time": "2023-06-11T22:28:36.572Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T22:30:58.119Z"
   },
   {
    "duration": 43,
    "start_time": "2023-06-11T22:30:58.135Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T22:30:58.180Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T22:30:58.191Z"
   },
   {
    "duration": 579,
    "start_time": "2023-06-11T22:30:58.202Z"
   },
   {
    "duration": 24506,
    "start_time": "2023-06-11T22:30:58.785Z"
   },
   {
    "duration": 599,
    "start_time": "2023-06-11T22:31:23.293Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-11T22:31:23.894Z"
   },
   {
    "duration": 34,
    "start_time": "2023-06-11T22:31:23.913Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T22:34:04.863Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T22:34:06.044Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T22:34:07.000Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T22:34:07.581Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T22:34:08.413Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-11T22:34:11.329Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T22:34:12.893Z"
   },
   {
    "duration": 29,
    "start_time": "2023-06-11T22:34:14.490Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T22:34:15.773Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T22:34:16.520Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T22:34:17.460Z"
   },
   {
    "duration": 4852,
    "start_time": "2023-06-11T22:35:30.355Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-11T22:35:35.209Z"
   },
   {
    "duration": 858,
    "start_time": "2023-06-11T22:35:35.213Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-11T22:35:36.075Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-11T22:35:36.116Z"
   },
   {
    "duration": 4666,
    "start_time": "2023-06-11T22:35:36.134Z"
   },
   {
    "duration": 221,
    "start_time": "2023-06-11T22:35:40.802Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T22:35:41.024Z"
   },
   {
    "duration": 57,
    "start_time": "2023-06-11T22:35:41.030Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-11T22:35:41.089Z"
   },
   {
    "duration": 3338,
    "start_time": "2023-06-11T22:35:41.108Z"
   },
   {
    "duration": 2801,
    "start_time": "2023-06-11T22:35:44.448Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T22:35:47.250Z"
   },
   {
    "duration": 397,
    "start_time": "2023-06-11T22:35:47.259Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-11T22:35:47.659Z"
   },
   {
    "duration": 395187,
    "start_time": "2023-06-11T22:35:47.686Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T22:42:22.874Z"
   },
   {
    "duration": 94,
    "start_time": "2023-06-11T22:42:22.889Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-11T22:42:22.984Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-11T22:42:23.013Z"
   },
   {
    "duration": 5616,
    "start_time": "2023-06-11T22:42:23.038Z"
   },
   {
    "duration": 874,
    "start_time": "2023-06-11T22:42:28.677Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-11T22:42:29.552Z"
   },
   {
    "duration": 107,
    "start_time": "2023-06-11T22:42:29.642Z"
   },
   {
    "duration": 912262,
    "start_time": "2023-06-11T22:42:29.751Z"
   },
   {
    "duration": 155922,
    "start_time": "2023-06-11T22:57:42.015Z"
   },
   {
    "duration": 72,
    "start_time": "2023-06-11T23:00:17.939Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-11T23:00:18.012Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-11T23:00:18.048Z"
   },
   {
    "duration": 58,
    "start_time": "2023-06-11T23:00:18.054Z"
   },
   {
    "duration": 583,
    "start_time": "2023-06-11T23:00:18.114Z"
   },
   {
    "duration": 27385,
    "start_time": "2023-06-11T23:00:18.698Z"
   },
   {
    "duration": 762,
    "start_time": "2023-06-11T23:00:46.085Z"
   },
   {
    "duration": 36,
    "start_time": "2023-06-11T23:00:46.853Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-11T23:00:46.890Z"
   },
   {
    "duration": 81,
    "start_time": "2023-06-11T23:00:46.933Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T23:00:47.016Z"
   },
   {
    "duration": 63,
    "start_time": "2023-06-11T23:00:47.032Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-11T23:00:47.098Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T23:00:47.129Z"
   },
   {
    "duration": 78,
    "start_time": "2023-06-11T23:00:47.153Z"
   },
   {
    "duration": 118,
    "start_time": "2023-06-11T23:00:47.233Z"
   },
   {
    "duration": 104,
    "start_time": "2023-06-11T23:00:47.353Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T23:00:47.459Z"
   },
   {
    "duration": 42,
    "start_time": "2023-06-11T23:00:47.473Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T23:00:47.520Z"
   },
   {
    "duration": 805,
    "start_time": "2023-06-11T23:36:21.494Z"
   },
   {
    "duration": 6098,
    "start_time": "2023-06-11T23:38:29.903Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T23:42:37.995Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T23:42:38.913Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T23:42:46.494Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T23:42:47.417Z"
   },
   {
    "duration": 4925,
    "start_time": "2023-06-11T23:47:23.376Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T23:47:28.312Z"
   },
   {
    "duration": 975,
    "start_time": "2023-06-11T23:47:28.325Z"
   },
   {
    "duration": 51,
    "start_time": "2023-06-11T23:47:29.302Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T23:47:29.366Z"
   },
   {
    "duration": 5746,
    "start_time": "2023-06-11T23:47:29.387Z"
   },
   {
    "duration": 275,
    "start_time": "2023-06-11T23:47:35.135Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T23:47:35.412Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-11T23:47:35.418Z"
   },
   {
    "duration": 68,
    "start_time": "2023-06-11T23:47:35.448Z"
   },
   {
    "duration": 4315,
    "start_time": "2023-06-11T23:47:35.518Z"
   },
   {
    "duration": 3333,
    "start_time": "2023-06-11T23:47:39.835Z"
   },
   {
    "duration": 425,
    "start_time": "2023-06-11T23:47:43.170Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-11T23:47:43.599Z"
   },
   {
    "duration": 581358,
    "start_time": "2023-06-11T23:47:43.620Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T23:57:24.980Z"
   },
   {
    "duration": 101,
    "start_time": "2023-06-11T23:57:24.988Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-11T23:57:25.098Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T23:57:25.112Z"
   },
   {
    "duration": 7367,
    "start_time": "2023-06-11T23:57:25.122Z"
   },
   {
    "duration": 1127,
    "start_time": "2023-06-11T23:57:32.547Z"
   },
   {
    "duration": 168,
    "start_time": "2023-06-11T23:57:33.682Z"
   },
   {
    "duration": 196229,
    "start_time": "2023-06-11T23:57:33.863Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.095Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.097Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.100Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.100Z"
   },
   {
    "duration": 1,
    "start_time": "2023-06-12T00:00:50.102Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.104Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.123Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.126Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.127Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.129Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.131Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.132Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.134Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.135Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.137Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.138Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.140Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.141Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.150Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.151Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T00:00:50.153Z"
   },
   {
    "duration": 6883,
    "start_time": "2023-06-12T00:01:03.036Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T00:01:09.923Z"
   },
   {
    "duration": 1005,
    "start_time": "2023-06-12T00:01:09.928Z"
   },
   {
    "duration": 70,
    "start_time": "2023-06-12T00:01:10.935Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T00:01:11.009Z"
   },
   {
    "duration": 5678,
    "start_time": "2023-06-12T00:01:11.015Z"
   },
   {
    "duration": 234,
    "start_time": "2023-06-12T00:01:16.696Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T00:01:16.931Z"
   },
   {
    "duration": 68,
    "start_time": "2023-06-12T00:01:16.942Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-12T00:01:17.012Z"
   },
   {
    "duration": 4291,
    "start_time": "2023-06-12T00:01:17.031Z"
   },
   {
    "duration": 3615,
    "start_time": "2023-06-12T00:01:21.324Z"
   },
   {
    "duration": 420,
    "start_time": "2023-06-12T00:01:24.941Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-12T00:01:25.369Z"
   },
   {
    "duration": 421757,
    "start_time": "2023-06-12T00:01:25.399Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-12T00:08:27.162Z"
   },
   {
    "duration": 34,
    "start_time": "2023-06-12T00:08:27.194Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T00:08:27.230Z"
   },
   {
    "duration": 47,
    "start_time": "2023-06-12T00:08:27.237Z"
   },
   {
    "duration": 3794,
    "start_time": "2023-06-12T00:08:27.285Z"
   },
   {
    "duration": 1038,
    "start_time": "2023-06-12T00:08:31.155Z"
   },
   {
    "duration": 101,
    "start_time": "2023-06-12T00:08:32.248Z"
   },
   {
    "duration": 886640,
    "start_time": "2023-06-12T00:08:32.351Z"
   },
   {
    "duration": 147320,
    "start_time": "2023-06-12T00:23:18.992Z"
   },
   {
    "duration": 59,
    "start_time": "2023-06-12T00:25:46.314Z"
   },
   {
    "duration": 36,
    "start_time": "2023-06-12T00:25:46.380Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T00:25:46.418Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T00:25:46.425Z"
   },
   {
    "duration": 554,
    "start_time": "2023-06-12T00:25:46.434Z"
   },
   {
    "duration": 3603,
    "start_time": "2023-06-12T00:25:46.990Z"
   },
   {
    "duration": 699,
    "start_time": "2023-06-12T00:25:50.595Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-12T00:25:51.296Z"
   },
   {
    "duration": 42,
    "start_time": "2023-06-12T00:25:51.321Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T00:25:51.365Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-12T00:25:51.376Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T00:25:51.400Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-12T00:25:51.411Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-12T00:25:51.432Z"
   },
   {
    "duration": 60,
    "start_time": "2023-06-12T00:25:51.441Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T00:25:51.502Z"
   },
   {
    "duration": 57,
    "start_time": "2023-06-12T00:25:51.522Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T00:25:51.584Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-12T00:25:51.601Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T00:25:51.614Z"
   },
   {
    "duration": 2748,
    "start_time": "2023-06-12T06:50:28.305Z"
   },
   {
    "duration": 1857,
    "start_time": "2023-06-12T07:05:36.428Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T07:06:53.539Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-12T07:06:54.803Z"
   },
   {
    "duration": 2399,
    "start_time": "2023-06-12T07:06:56.739Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-12T07:06:59.140Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T07:07:01.027Z"
   },
   {
    "duration": 3850,
    "start_time": "2023-06-12T07:07:03.613Z"
   },
   {
    "duration": 143,
    "start_time": "2023-06-12T07:07:07.476Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T07:07:15.122Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-12T07:07:16.193Z"
   },
   {
    "duration": 3834,
    "start_time": "2023-06-12T07:07:25.889Z"
   },
   {
    "duration": 9531,
    "start_time": "2023-06-12T07:07:29.725Z"
   },
   {
    "duration": 385,
    "start_time": "2023-06-12T07:07:39.258Z"
   },
   {
    "duration": 29,
    "start_time": "2023-06-12T07:07:39.645Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-12T07:07:39.677Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-12T07:07:45.793Z"
   },
   {
    "duration": 177986,
    "start_time": "2023-06-12T07:07:48.218Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T07:10:46.207Z"
   },
   {
    "duration": 65,
    "start_time": "2023-06-12T07:10:46.214Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T07:10:46.282Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-12T07:10:46.290Z"
   },
   {
    "duration": 5776,
    "start_time": "2023-06-12T07:10:46.314Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:12:45.763Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T13:12:46.153Z"
   },
   {
    "duration": 762,
    "start_time": "2023-06-12T13:12:47.110Z"
   },
   {
    "duration": 32,
    "start_time": "2023-06-12T13:12:48.566Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:12:54.360Z"
   },
   {
    "duration": 3591,
    "start_time": "2023-06-12T13:12:56.215Z"
   },
   {
    "duration": 140,
    "start_time": "2023-06-12T13:12:59.808Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T13:13:04.916Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-12T13:13:07.490Z"
   },
   {
    "duration": 3379,
    "start_time": "2023-06-12T13:13:12.565Z"
   },
   {
    "duration": 1983,
    "start_time": "2023-06-12T13:13:15.945Z"
   },
   {
    "duration": 327,
    "start_time": "2023-06-12T13:13:17.929Z"
   },
   {
    "duration": 26,
    "start_time": "2023-06-12T13:13:18.258Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T13:13:18.286Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T13:13:19.769Z"
   },
   {
    "duration": 216553,
    "start_time": "2023-06-12T13:13:21.557Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:16:58.112Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-12T13:16:58.174Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T13:16:58.207Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T13:16:58.213Z"
   },
   {
    "duration": 3264,
    "start_time": "2023-06-12T13:16:58.223Z"
   },
   {
    "duration": 227,
    "start_time": "2023-06-12T13:17:10.649Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T13:17:53.764Z"
   },
   {
    "duration": 2163,
    "start_time": "2023-06-12T13:18:07.612Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:18:32.887Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T13:18:34.677Z"
   },
   {
    "duration": 646,
    "start_time": "2023-06-12T13:18:35.803Z"
   },
   {
    "duration": 32,
    "start_time": "2023-06-12T13:18:37.157Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:18:40.400Z"
   },
   {
    "duration": 3806,
    "start_time": "2023-06-12T13:18:43.757Z"
   },
   {
    "duration": 138,
    "start_time": "2023-06-12T13:18:53.505Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T13:19:06.863Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-12T13:19:07.682Z"
   },
   {
    "duration": 3266,
    "start_time": "2023-06-12T13:19:14.217Z"
   },
   {
    "duration": 1997,
    "start_time": "2023-06-12T13:19:17.486Z"
   },
   {
    "duration": 34506,
    "start_time": "2023-06-12T13:19:25.763Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.272Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.274Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.275Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.277Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.278Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.279Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.281Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.282Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T13:20:00.283Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T13:20:21.087Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-12T13:20:21.562Z"
   },
   {
    "duration": 653,
    "start_time": "2023-06-12T13:20:21.874Z"
   },
   {
    "duration": 43,
    "start_time": "2023-06-12T13:20:22.529Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T13:20:22.665Z"
   },
   {
    "duration": 3771,
    "start_time": "2023-06-12T13:20:23.065Z"
   },
   {
    "duration": 152,
    "start_time": "2023-06-12T13:20:26.838Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T13:20:26.992Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-12T13:20:27.000Z"
   },
   {
    "duration": 2783,
    "start_time": "2023-06-12T13:20:30.397Z"
   },
   {
    "duration": 2118,
    "start_time": "2023-06-12T13:20:33.182Z"
   },
   {
    "duration": 3059,
    "start_time": "2023-06-12T13:20:35.303Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-12T13:20:38.365Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T13:20:38.387Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T13:20:38.395Z"
   },
   {
    "duration": 4518,
    "start_time": "2023-06-12T13:43:34.180Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T13:43:38.700Z"
   },
   {
    "duration": 2389,
    "start_time": "2023-06-12T13:43:38.704Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-12T13:43:41.095Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T13:43:41.129Z"
   },
   {
    "duration": 4210,
    "start_time": "2023-06-12T13:43:41.137Z"
   },
   {
    "duration": 176,
    "start_time": "2023-06-12T13:43:45.349Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T13:43:45.527Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-12T13:43:45.534Z"
   },
   {
    "duration": 4248,
    "start_time": "2023-06-12T13:43:45.587Z"
   },
   {
    "duration": 9103,
    "start_time": "2023-06-12T13:43:49.837Z"
   },
   {
    "duration": 3245,
    "start_time": "2023-06-12T13:43:58.942Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T13:44:02.188Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-12T13:44:02.204Z"
   },
   {
    "duration": 29,
    "start_time": "2023-06-12T13:44:02.219Z"
   },
   {
    "duration": 2808122,
    "start_time": "2023-06-12T13:44:02.250Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T14:30:50.374Z"
   },
   {
    "duration": 61,
    "start_time": "2023-06-12T14:30:50.384Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-12T14:30:50.447Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-12T14:30:50.459Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T14:30:50.505Z"
   },
   {
    "duration": 13063,
    "start_time": "2023-06-12T14:30:50.512Z"
   },
   {
    "duration": 2501,
    "start_time": "2023-06-12T14:31:03.587Z"
   },
   {
    "duration": 99,
    "start_time": "2023-06-12T14:31:06.092Z"
   },
   {
    "duration": 769179,
    "start_time": "2023-06-12T14:31:06.197Z"
   },
   {
    "duration": 126119,
    "start_time": "2023-06-12T14:43:55.378Z"
   },
   {
    "duration": 58,
    "start_time": "2023-06-12T14:46:01.499Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-12T14:46:01.560Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-12T14:46:01.588Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-12T14:46:01.618Z"
   },
   {
    "duration": 32050,
    "start_time": "2023-06-12T14:46:01.660Z"
   },
   {
    "duration": 6375,
    "start_time": "2023-06-12T14:46:33.713Z"
   },
   {
    "duration": 56,
    "start_time": "2023-06-12T14:46:40.090Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-12T14:46:40.148Z"
   },
   {
    "duration": 328,
    "start_time": "2023-06-12T14:46:40.177Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.508Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.509Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.510Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.511Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.513Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.514Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.516Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.517Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T14:46:40.518Z"
   },
   {
    "duration": 202439,
    "start_time": "2023-06-12T15:09:54.149Z"
   },
   {
    "duration": 1783,
    "start_time": "2023-06-12T15:13:16.591Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-12T15:16:04.937Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-12T15:16:28.211Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-12T15:17:01.961Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-12T15:17:18.481Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-12T15:20:14.266Z"
   },
   {
    "duration": 27641,
    "start_time": "2023-06-12T15:20:23.038Z"
   },
   {
    "duration": 2611,
    "start_time": "2023-06-12T15:21:30.674Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-12T15:22:32.790Z"
   },
   {
    "duration": 8014,
    "start_time": "2023-06-12T15:22:54.959Z"
   },
   {
    "duration": 4138165,
    "start_time": "2023-06-12T15:40:37.761Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-13T03:32:33.358Z"
   }
  ],
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
